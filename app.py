import argparse
from collections import defaultdict
from search_engine import SemanticSearchEngine

def main():
    p = argparse.ArgumentParser(description='è©é¨™æª¢æ¸¬ CLI')
    p.add_argument('--csv', default='data/scam_data_tw.csv')
    p.add_argument('--threshold', type=float, default=0.85)
    args = p.parse_args()

    engine = SemanticSearchEngine(csv_path=args.csv, risk_threshold=args.threshold)
    print("âœ… å·²å°±ç·’ï¼Œè¼¸å…¥æ–‡å­—å¾Œé€²è¡Œ Top10 è¨ˆç®—ä¸¦è¼¸å‡º Top3 è©é¨™ç¨®é¡ (exit é›¢é–‹)ã€‚")

    while True:
        q = input("\nğŸ” æª¢æ¸¬å…§å®¹ï¼š")
        if q.lower() in ('exit', 'quit'):
            break

        # å–å¾— Top10 çµæœ
        top10 = engine.search(q, top_k=10)
        # æŒ‰è©é¨™ç¨®é¡å½™æ•´ similarity
        type_scores = defaultdict(list)
        for r in top10:
            type_scores[r['type']].append(r['score'])
        # è¨ˆç®—æ¯é¡æœ€é«˜ç›¸ä¼¼åº¦ï¼Œä¸¦æ’åºå–å‰ä¸‰
        top_types = sorted(
            ((t, max(scores)) for t, scores in type_scores.items()),
            key=lambda x: x[1], reverse=True
        )[:3]

        print("\nğŸ“Š æœ€å¯èƒ½çš„ 3 ç¨®è©é¨™é¡å‹ï¼š")
        for t, sc in top_types:
            print(f" - {t} (æœ€é«˜ç›¸ä¼¼åº¦: {sc:.4f})")

        # é—œéµè©é«˜äº®
        hits, hl = engine.highlight_keywords(q)
        if hits:
            print(f"ğŸ”‘ é—œéµè©ï¼š{', '.join(hits)}")
            print(f"æ¨™ç¤ºå¾Œï¼š{hl}")

        print('æ›´å¤šè³‡æºï¼šhttps://165.npa.gov.tw')

if __name__ == '__main__':
    main()